## SSD300 Pascal VOC 07+12 Training Summary
---

이는 동일한 모델의 원래 카페인이 구현된 것과 동일한 구성을 사용하는 Pascal VOC 2007 "열차" 및 2012년 "열차" 이미지 세트에 대한 SSD300 교육을 요약한 것입니다.

원래 Caffe SSD 구현 상태의 SSD 페이퍼나 GitHub 저장소는 교육 진행 상황에 대한 세부 정보가 아니라 최종 평가 결과만 제공하므로, 일부는 여기에 제공된 손실 곡선 및 중간 mAP 평가 결과를 자체 교육과의 비교에 도움이 될 수 있습니다.

아래에는 기존의 SSD300 "07+12" 모델의 교육 구성을 복제할 수 있도록 모든 매개 변수가 이미 사전 설정된 노트북 실행에 대한 교육 결과가 나와 있습니다. 한 가지 작은 변화를 시도했습니다. 32배 크기 OOM 오류도 종종 발생하고, 31배치 크기 훈련도 했습니다.

아래에 나와 있는 데이터에 대한 중요 사항은 다음과 같습니다.

SGD는 교육 시작 시 기본적으로 불안정합니다. 최적화는 확률적입니다. 즉, 새로운 교육을 10번 시작하면 첫 번째 교육 단계의 손실 패턴이 매번 다르게 보일 수 있습니다. SGD의 경우 매우 다르게 보입니다. 한 번은 시작부터 손실이 부드럽게 감소하는 경우가 있었는데, 이것이 바로 제 경우입니다. 또 한 번, 수백 번의 훈련 과정 동안 아무 일도 일어나지 않는 것처럼 보이는 매우 이른 시기에 손실이 일시적으로 고원에 갇히게 될 수도 있습니다. 그러나 또 한번의 패배는 시작하자마자 폭발해 NaN이 될 수도 있습니다. 손실이 NaN이 되지 않는 한, 최종 정합화 손실은 교육 초기 단계의 손실 진행에 크게 의존하지 않습니다. 다시 말해, 비록 처음에는 손실이 빨리 감소하지 않더라도, 여러분은 여전히 같은 정합화 손실을 입게 될 것이고, 거기에 도달하는 데 더 오랜 시간이 걸릴 것입니다. 벤치마크로, 처음 1,000번의 교육 단계를 거친 후 저는 10~15번의 교육 손실에 대한 가치로 보았습니다. 애덤 옵티마이저(Adam Optimizer)는 같은 정도의 변동성을 겪지 않으며, 분명히 우수한 최적화 도구입니다. 하지만 원래의 카페(Caffe) 모델은 SGD로 훈련되었기 때문에 저는 원래 결과를 재현하기 위해 그것을 사용했습니다.

### Training and Validation Loss

아래에 나와 있는 내용은 1,000개의 교육 단계마다 교육 및 검증 손실입니다. 검증 손실은 Pascal VOC 2007 '테스트' 이미지 세트로 계산됩니다. 제 경우, 검증 손실이 수렴되는 데 예상된 12만 번이 아니라 약 10만 5천 번 정도 밖에 걸리지 않았습니다. 그러나 위에서 설명한 바와 같이, 시간이 더 오래 걸릴 수 있습니다. 56,000개의 교육 단계를 통해 학습 속도를 0.001에서 0.0001로 낮췄습니다. 원래의 학습 속도 일정은 8만 번의 교육 과정 후에만 이러한 감소가 계획됩니다. 하지만 제 경우 처음에는 손실이 너무 빨리 감소했기 때문에, 저는 일찍 학습 속도를 줄여야 했습니다. 7만 6천 개의 교육 단계를 거치고 학습 속도를 0.00001로 줄여서 그 단계로부터 일정하게 유지했습니다.

![loss_history](ssd300_pascal_07+12_loss_history.png)

### Mean Average Precision

공식 Pascal VOCdvkit 2007 Matlab 평가 코드를 사용하여 평가한 Pascal VOC 2007 테스트의 중간 및 최종 mAP 값입니다. 이 표에는 20,000개의 교육 단계마다 최고의 값이 나와 있습니다. 다시 한 번, 교육 초기 단계에 따라 진행 속도가 느려질 수 있습니다. 같은 구성으로 시작한 또 다른 훈련에서는 처음 20,000번의 훈련 단계를 거친 후에 겨우 0.665의 mAP를 받았습니다. 교육 단계 102,000 이후의 전체 모델을 다운로드할 수 있습니다. [here](https://drive.google.com/open?id=1-MYYaZbIHNPtI2zzklgVBAjssbP06BeA).

|             | Steps |  20k     |  40k     |  60k     |  80k     |  100k    |  102k    |
|-------------|-------|----------|----------|----------|----------|----------|----------|
|aeroplane    |  AP   |  0.6874  |  0.7401  |  0.7679  |  0.7827  |  0.7912  |  0.7904  |
|bicycle      |  AP   |  0.7786  |  0.8203  |  0.795   |  0.8436  |  0.8453  |  0.8466  |
|bird         |  AP   |  0.6855  |  0.6939  |  0.7191  |  0.7564  |  0.7655  |  0.7672  |
|boat         |  AP   |  0.5804  |  0.6173  |  0.6258  |  0.6866  |  0.6896  |  0.6952  |
|bottle       |  AP   |  0.3449  |  0.4288  |  0.453   |  0.4681  |  0.4896  |  0.4844  |
|bus          |  AP   |  0.7771  |  0.8332  |  0.8343  |  0.8525  |  0.8537  |  0.8554  |
|car          |  AP   |  0.8048  |  0.8435  |  0.8345  |  0.848   |  0.8546  |  0.8543  |
|cat          |  AP   |  0.852   |  0.7989  |  0.8551  |  0.8759  |  0.8727  |  0.8746  |
|chair        |  AP   |  0.5085  |  0.5548  |  0.5287  |  0.5873  |  0.5895  |  0.5911  |
|cow          |  AP   |  0.7359  |  0.7821  |  0.791   |  0.8278  |  0.8271  |  0.8243  |
|diningtable  |  AP   |  0.6805  |  0.7181  |  0.7502  |  0.7543  |  0.7733  |  0.7614  |
|dog          |  AP   |  0.8118  |  0.7898  |  0.8222  |  0.8546  |  0.8544  |  0.8552  |
|horse        |  AP   |  0.823   |  0.8501  |  0.8532  |  0.8586  |  0.8688  |  0.867   |
|motorbike    |  AP   |  0.7725  |  0.7935  |  0.8081  |  0.845   |  0.8471  |  0.8509  |
|person       |  AP   |  0.73    |  0.7514  |  0.7634  |  0.7851  |  0.7869  |  0.7862  |
|pottedplant  |  AP   |  0.4112  |  0.4335  |  0.4982  |  0.5051  |  0.5131  |  0.5182  |
|sheep        |  AP   |  0.6821  |  0.7324  |  0.7283  |  0.7717  |  0.7783  |  0.7799  |
|sofa         |  AP   |  0.7417  |  0.7824  |  0.7663  |  0.7928  |  0.7911  |  0.794   |
|train        |  AP   |  0.7942  |  0.8169  |  0.8326  |  0.867   |  0.862   |  0.8596  |
|tvmonitor    |  AP   |  0.725   |  0.7301  |  0.7259  |  0.7589  |  0.7649  |  0.7651  |
|             |**mAP**|**0.696** |**0.726** |**0.738** |**0.766** |**0.7709**|**0.7711**|
